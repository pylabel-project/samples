{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github//pylabel-project/samples/blob/main/pylabel2azure_custom_vision.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> \n",
    "# Upload Annotations to Azure Custom Vision \n",
    "Custom Vision, part of the Azure Cognitive Services family, is a solution for training and deploying custom computer vision models. Custom Vision includes an API to upload images and annotations to train a custom model. Using PyLabel you can import existing labels in COCO, YOLOv5, or VOC format and then upload the dataset to Custom Vision.  \n",
    "\n",
    "This notebook demonstrates how to import a custom dataset in YOLO format to Custom Vision. To complete the steps you will need an Azure Account and a Custom Vision subscription. Follow [this tutorial on the the Custom Vision site](https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/quickstarts/object-detection?tabs=visual-studio&pivots=programming-language-python) to setup your account and make sure it is working before using this notebook to import a custom dataset. When you are ready to use this notebook to upload a custom dataset, it is recommended to open https://www.customvision.ai/ so you can see the results of the commands you are performing through the API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Azure cognitive services libraries \n",
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "\n",
    "#Import other libraries used in this notebook \n",
    "import os, zipfile\n",
    "from pathlib import PurePath\n",
    "from os.path import exists\n",
    "from decimal import *\n",
    "\n",
    "from pylabel import importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your Azure endpoint and subscription keys.\n",
    "ENDPOINT = \"\"\n",
    "training_key = \"\"\n",
    "prediction_key = \"\"\n",
    "prediction_resource_id = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize objects used by Azure Congitive vision\n",
    "credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\n",
    "trainer = CustomVisionTrainingClient(ENDPOINT, credentials)\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\n",
    "predictor = CustomVisionPredictionClient(ENDPOINT, prediction_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new project\n",
    "publish_iteration_name = \"detectModel\"\n",
    "obj_detection_domain = next(domain for domain in trainer.get_domains() if domain.type == \"ObjectDetection\" and domain.name == \"General\")\n",
    "project = trainer.create_project(\"PyLabel Sample Dataset\", domain_id=obj_detection_domain.id)\n",
    "#If you browse to https://www.customvision.ai/ you should see a new project called \"PyLabel Sample Dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Custom Dataset \n",
    "For this demonstration we will download 100 images from the <a href=\"https://github.com/pylabel-project/datasets_models#squirrels-and-nuts\">squirrels and nuts dataset with annotations in YOLOv5 format.</a> PyLabel can also import datasets in COCO and PASCAL VOC format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "os.makedirs(\"data/\", exist_ok=True)\n",
    "!wget \"https://github.com/pylabel-project/datasets_models/blob/main/squirrelsandnuts/squirrelsandnuts_train.zip?raw=true\" -O data/squirrelsandnuts_train.zip\n",
    "with zipfile.ZipFile(\"data/squirrelsandnuts_train.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_folder</th>\n",
       "      <th>img_filename</th>\n",
       "      <th>img_path</th>\n",
       "      <th>img_id</th>\n",
       "      <th>img_width</th>\n",
       "      <th>img_height</th>\n",
       "      <th>img_depth</th>\n",
       "      <th>ann_segmented</th>\n",
       "      <th>ann_bbox_xmin</th>\n",
       "      <th>ann_bbox_ymin</th>\n",
       "      <th>...</th>\n",
       "      <th>ann_segmentation</th>\n",
       "      <th>ann_iscrowd</th>\n",
       "      <th>ann_pose</th>\n",
       "      <th>ann_truncated</th>\n",
       "      <th>ann_difficult</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>cat_name</th>\n",
       "      <th>cat_supercategory</th>\n",
       "      <th>split</th>\n",
       "      <th>annotated</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../images/train</td>\n",
       "      <td>2021-07-03T06-30-10-frame_0001.jpeg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>960</td>\n",
       "      <td>540</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>255.024</td>\n",
       "      <td>170.991</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Squirrel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../images/train</td>\n",
       "      <td>2021-07-03T06-47-39-frame_0004.jpeg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>960</td>\n",
       "      <td>540</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>650.016</td>\n",
       "      <td>447.984</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Nut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../images/train</td>\n",
       "      <td>2021-07-03T06-47-39-frame_0004.jpeg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>960</td>\n",
       "      <td>540</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>690.480</td>\n",
       "      <td>422.010</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Nut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            img_folder                         img_filename img_path  img_id  \\\n",
       "id                                                                             \n",
       "0   ../../images/train  2021-07-03T06-30-10-frame_0001.jpeg      NaN       0   \n",
       "1   ../../images/train  2021-07-03T06-47-39-frame_0004.jpeg      NaN       1   \n",
       "2   ../../images/train  2021-07-03T06-47-39-frame_0004.jpeg      NaN       1   \n",
       "\n",
       "    img_width  img_height  img_depth ann_segmented  ann_bbox_xmin  \\\n",
       "id                                                                  \n",
       "0         960         540          3           NaN        255.024   \n",
       "1         960         540          3           NaN        650.016   \n",
       "2         960         540          3           NaN        690.480   \n",
       "\n",
       "    ann_bbox_ymin  ...  ann_segmentation  ann_iscrowd  ann_pose  \\\n",
       "id                 ...                                            \n",
       "0         170.991  ...               NaN          NaN       NaN   \n",
       "1         447.984  ...               NaN          NaN       NaN   \n",
       "2         422.010  ...               NaN          NaN       NaN   \n",
       "\n",
       "    ann_truncated  ann_difficult cat_id  cat_name cat_supercategory split  \\\n",
       "id                                                                          \n",
       "0             NaN            NaN      0  Squirrel               NaN   NaN   \n",
       "1             NaN            NaN      1       Nut               NaN   NaN   \n",
       "2             NaN            NaN      1       Nut               NaN   NaN   \n",
       "\n",
       "   annotated  \n",
       "id            \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import annotations as a PyLabel dataset\n",
    "dataset = importer.ImportYoloV5(path=\"data/squirrelsandnuts_train/labels/train\",\n",
    "        path_to_images=\"../../images/train\", \n",
    "        img_ext=\"jpeg\",\n",
    "        cat_names=['Squirrel','Nut']\n",
    "    )\n",
    "dataset.df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import to Azure Custom Vision\n",
    "PyLabel stores the annotations as a pandas dataframe. Now you can use extract the annotations from the dataframe and use it as inputs to the Custom Vision APIs. \n",
    "\n",
    "The first step is to create tags for each of the classes in your custom dataset. A list of class names is available in the dataset.analyze.classes property. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Squirrel', 'Nut']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.analyze.classes)\n",
    "#Create a tag for each class and store then in a dict where the class name is the key\n",
    "tags = {}\n",
    "for class_name in dataset.analyze.classes:\n",
    "    tag = trainer.create_tag(project.id, class_name)\n",
    "    tags[class_name] = tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if you check your account on https://www.customvision.ai/ you should see a new project called \"PyLabel Sample Dataset\" with 2 tags added: Squirrels and Nuts. \n",
    "\n",
    "You are ready to upload your images and annotations. For each image in your dataset you will need to add \"Regions\" for each bounding box and then upload the image and annotations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload complete\n"
     ]
    }
   ],
   "source": [
    "#Iterate the rows for each image in the dataframe\n",
    "for img_filename, img_df in dataset.df.groupby('img_filename'):\n",
    "    img_path = str(PurePath(dataset.path_to_annotations, str(img_df.iloc[0].img_folder), img_filename))\n",
    "    assert exists(img_path), f\"File does not exist: {img_path}\"\n",
    "\n",
    "    #Create a region object for each bounding box in the dataset \n",
    "    regions = []\n",
    "    for index, row in img_df.iterrows():\n",
    "\n",
    "        #Normalize the boundings box coordinates between 0 and 1\n",
    "        x = Decimal(row.ann_bbox_xmin / row.img_width).min(1)\n",
    "        y = Decimal(row.ann_bbox_ymin / row.img_height).min(1)\n",
    "        w = Decimal(row.ann_bbox_width / row.img_width).min(1-x)\n",
    "        h = Decimal(row.ann_bbox_height / row.img_height).min(1-y)\n",
    "        \n",
    "        regions.append(Region(\n",
    "                tag_id=tags[row.cat_name].id, \n",
    "                left=x,\n",
    "                top=y,\n",
    "                width=w,\n",
    "                height=h\n",
    "            )\n",
    "        )\n",
    "\n",
    "    #Create an object with the image and all of the annotations for that image\n",
    "    with open(img_path, mode=\"rb\") as image_contents:\n",
    "        image_and_annotations = [ImageFileCreateEntry(name=img_filename, contents=image_contents.read(), regions=regions)]\n",
    "\n",
    "    #Upload the image and all annnotations for that image\n",
    "    upload_result = trainer.create_images_from_files(\n",
    "            project.id, \n",
    "            ImageFileCreateBatch(images=image_and_annotations)\n",
    "        )\n",
    "    \n",
    "    #If upload is not successful, print details about that image for debugging \n",
    "    if not upload_result.is_batch_successful:\n",
    "        print(\"Image upload failed.\")\n",
    "        for image in upload_result.images:\n",
    "            print(img_path)\n",
    "            print(\"Image status: \", image.status)\n",
    "            print(regions)\n",
    "\n",
    "#This will take a few minutes \n",
    "print(\"Upload complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should see all of your images uploaded to https://www.customvision.ai/.\n",
    "<p>\n",
    "<img src=\"https://raw.githubusercontent.com/pylabel-project/datasets_models/main/pylabel_assets/custom_vision_project.png\" width=400>\n",
    "<p>\n",
    "Click and image to see the bounding boxes.\n",
    "<p>\n",
    "<img src=\"https://raw.githubusercontent.com/pylabel-project/datasets_models/main/pylabel_assets/custom_vision_image.png\" width=400>\n",
    "<p>\n",
    "\n",
    "Now you are ready to train a model, which you can do at https://www.customvision.ai/. \n",
    "- If find a problem with this notebook, please report it as an issue here: https://github.com/pylabel-project/pylabel/issues \n",
    "- If have other questions, please start a discussion here: https://github.com/pylabel-project/pylabel/discussions. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "224f10583582cbeb83347e66d7d5874fb4e3ef8613e486088287d7c0b66e9aac"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
